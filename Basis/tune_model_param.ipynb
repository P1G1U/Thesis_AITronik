{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 12:35:52.206200: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-03-22 12:35:52.206367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 256 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import model as m\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "os.environ[\"TF_CPP_VMODULE\"]=\"gpu_process_state=10,gpu_cudamallocasync_allocator=10\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.set_logical_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.LogicalDeviceConfiguration(memory_limit=256)])\n",
    "\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 12:37:27.321381: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:288] gpu_async_0 cuMemAllocAsync failed to allocate 188743680 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 197459968/2095448064\n",
      "2022-03-22 12:37:27.321426: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:293] Stats: Limit:                       268435456\n",
      "InUse:                       959058036\n",
      "MaxInUse:                   1145997900\n",
      "NumAllocs:                       56998\n",
      "MaxAllocSize:                188743680\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-03-22 12:37:27.321442: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2022-03-22 12:37:27.321450: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 24\n",
      "2022-03-22 12:37:27.321456: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 9\n",
      "2022-03-22 12:37:27.321462: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12, 5\n",
      "2022-03-22 12:37:27.321468: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 128, 6\n",
      "2022-03-22 12:37:27.321474: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 256, 6\n",
      "2022-03-22 12:37:27.321479: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 512, 5\n",
      "2022-03-22 12:37:27.321485: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1024, 6\n",
      "2022-03-22 12:37:27.321491: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1\n",
      "2022-03-22 12:37:27.321504: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1408, 6\n",
      "2022-03-22 12:37:27.321510: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1536, 5\n",
      "2022-03-22 12:37:27.321517: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4096, 5\n",
      "2022-03-22 12:37:27.321523: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 5424, 2\n",
      "2022-03-22 12:37:27.321530: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16272, 2\n",
      "2022-03-22 12:37:27.321544: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 40960, 6\n",
      "2022-03-22 12:37:27.321551: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 327680, 6\n",
      "2022-03-22 12:37:27.321558: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 524288, 5\n",
      "2022-03-22 12:37:27.321565: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1301760, 2\n",
      "2022-03-22 12:37:27.321572: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3905280, 2\n",
      "2022-03-22 12:37:27.321586: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 188743680, 5\n",
      "2022-03-22 12:37:27.321615: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at constant_op.cc:175 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[46080,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 639, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 825, in _create_all_weights\n        self._create_slots(var_list)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py\", line 119, in _create_slots\n        self.add_slot(var, 'v')\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 911, in add_slot\n        weight = tf.Variable(\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/initializers/initializers_v2.py\", line 145, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: OOM when allocating tensor with shape[46080,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0 [Op:Fill]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/tune_model_param.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/tune_model_param.ipynb#ch0000001?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39mmodel_compile(\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,model\u001b[39m.\u001b[39mpos_loss,[\u001b[39m'\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/tune_model_param.ipynb#ch0000001?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mgroup_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/tune_model_param.ipynb#ch0000001?line=19'>20</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mmodel_run(group_epochs,batch_size, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/tune_model_param.ipynb#ch0000001?line=20'>21</a>\u001b[0m     pos_mse,rot_mse,pos_mae,rot_mae \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_error(verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/tune_model_param.ipynb#ch0000001?line=21'>22</a>\u001b[0m     results\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m\"\u001b[39m:i,\u001b[39m\"\u001b[39m\u001b[39mdrop-out\u001b[39m\u001b[39m\"\u001b[39m:j,\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m:(step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mgroup_epochs,\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m:history,\u001b[39m\"\u001b[39m\u001b[39mposition squared error\u001b[39m\u001b[39m\"\u001b[39m:pos_mse, \u001b[39m\"\u001b[39m\u001b[39mrotation squared error\u001b[39m\u001b[39m\"\u001b[39m:rot_mse, \u001b[39m\"\u001b[39m\u001b[39mposition absolute error\u001b[39m\u001b[39m\"\u001b[39m:pos_mae, \u001b[39m\"\u001b[39m\u001b[39mrotation absolute error\u001b[39m\u001b[39m\"\u001b[39m:rot_mae})\n",
      "File \u001b[0;32m~/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py:72\u001b[0m, in \u001b[0;36mNN_Model.model_run\u001b[0;34m(self, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_run\u001b[39m(\u001b[39mself\u001b[39m, epochs, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_cnn\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_tensor\u001b[39m.\u001b[39;49mTR_features, \n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=72'>73</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_tensor\u001b[39m.\u001b[39;49mTR_targets, \n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=73'>74</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=74'>75</a>\u001b[0m         validation_data\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_tensor\u001b[39m.\u001b[39;49mTS_features, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_tensor\u001b[39m.\u001b[39;49mTS_targets),\n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=75'>76</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=76'>77</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size\n\u001b[1;32m     <a href='file:///home/ait_guest/Desktop/LP_thesis/Codice/thesis_AITronik/Basis/model.py?line=77'>78</a>\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/ait_guest/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 639, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 825, in _create_all_weights\n        self._create_slots(var_list)\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py\", line 119, in _create_slots\n        self.add_slot(var, 'v')\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 911, in add_slot\n        weight = tf.Variable(\n    File \"/home/ait_guest/.local/lib/python3.9/site-packages/keras/initializers/initializers_v2.py\", line 145, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: OOM when allocating tensor with shape[46080,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0 [Op:Fill]\n"
     ]
    }
   ],
   "source": [
    "model= m.NN_Model()\n",
    "model.get_data(\"laser_log/laser_log.csv\")\n",
    "\n",
    "beta=[0.2,0.8]\n",
    "drop=[0.3]\n",
    "epochs=12\n",
    "batch_size=16\n",
    "\n",
    "group_epochs=2\n",
    "\n",
    "results=[]\n",
    "\n",
    "for i in beta:\n",
    "    for j in drop:\n",
    "        #with sess.as_default():\n",
    "            model.model_define(drop_rate=j)\n",
    "            model.set_beta(i)\n",
    "            model.model_compile(\"adam\",model.pos_loss,['mean_absolute_error'])\n",
    "            for step in range(epochs//group_epochs):\n",
    "                history = model.model_run(group_epochs,batch_size, verbose=1)\n",
    "                pos_mse,rot_mse,pos_mae,rot_mae = model.get_error(verbose=1)\n",
    "                results.append({\"beta\":i,\"drop-out\":j,\"epochs\":(step+1)*group_epochs,\"history\":history,\"position squared error\":pos_mse, \"rotation squared error\":rot_mse, \"position absolute error\":pos_mae, \"rotation absolute error\":rot_mae})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results23k.csv', 'w') as f:\n",
    "    f.write(\"beta;dropout;epochs;pos_mse;pos_mae;rot_mse;rot_mae\\n\")\n",
    "    for item in results:\n",
    "        f.write(\"{};{};{};{};{};{};{}\\n\".format(item[\"beta\"],item[\"drop-out\"],item[\"epochs\"],item[\"position squared error\"],item[\"position absolute error\"],item[\"rotation squared error\"],item[\"rotation absolute error\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
